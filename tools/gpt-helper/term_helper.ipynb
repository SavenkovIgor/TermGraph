{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "413b2b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# print(openai.Engine.list())\n",
    "\n",
    "def print_lines(text, max_line_length=120):\n",
    "    lines = []\n",
    "    line = \"\"\n",
    "    for word in text.split():\n",
    "        if len(line + word) > max_line_length:\n",
    "            lines.append(line)\n",
    "            line = \"\"\n",
    "        line += word + \" \"\n",
    "    lines.append(line)\n",
    "\n",
    "    for line in lines:\n",
    "        print(line)\n",
    "\n",
    "class ChatEngine:\n",
    "    model = \"\"\n",
    "    temp = 0\n",
    "\n",
    "    def __init__(self, model=\"gpt-3.5-turbo\", temp=0):\n",
    "        self.model = model\n",
    "        self.temp = temp\n",
    "\n",
    "class Chat:\n",
    "    messages: list = []\n",
    "    engine: ChatEngine\n",
    "\n",
    "    def __init__(self, engine, system_message, user_messages = []):\n",
    "        self.engine = engine\n",
    "        self.messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "        self.messages.extend([{\"role\": \"user\", \"content\": message} for message in user_messages])\n",
    "\n",
    "    def get_answer(self, user_message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.engine.model,\n",
    "            messages=self.messages,\n",
    "            temperature=self.engine.temp,\n",
    "        )\n",
    "        answer = response.choices[0].message[\"content\"]\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b5b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "continue_term_prompt = \"\"\"You are a terms helper robot \\\n",
    "your task is to guess, based on the list of terms, \\\n",
    "which one term, not in the list, \\\n",
    "is the most relevant to already given terms.\"\"\"\n",
    "\n",
    "def load_global_static_data() -> dict:\n",
    "    with open(\"../../lib/StaticDataStorage/data/Global.json\", \"r\") as f:\n",
    "        globalJson = json.load(f)\n",
    "    \n",
    "    return globalJson\n",
    "\n",
    "def get_terms(globalJson: dict) -> list:\n",
    "    ret = []\n",
    "\n",
    "    for item in globalJson['terms']:\n",
    "        termDef = item['termDef']\n",
    "        term = termDef.split(\" - \")[0]\n",
    "        ret.append(term)\n",
    "\n",
    "    return ret\n",
    "\n",
    "def predict_next_term():\n",
    "    engine = ChatEngine()\n",
    "    chat = Chat(engine, continue_term_prompt)\n",
    "    globalJson = load_global_static_data()\n",
    "    terms = get_terms(globalJson)\n",
    "    terms_str = \", \".join(terms)\n",
    "    answer = chat.get_answer(terms_str)\n",
    "    print_lines(answer)\n",
    "\n",
    "predict_next_term()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
