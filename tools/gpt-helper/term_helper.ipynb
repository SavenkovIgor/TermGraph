{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b2b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "from typing import List, Dict, Any\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "def print_lines(text: str, max_line_length: int = 120):\n",
    "    lines: List[str] = []\n",
    "    line = \"\"\n",
    "    for word in text.split():\n",
    "        if len(line + word) > max_line_length:\n",
    "            lines.append(line)\n",
    "            line = \"\"\n",
    "        line += word + \" \"\n",
    "    lines.append(line)\n",
    "\n",
    "    for line in lines:\n",
    "        print(line)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TermData:\n",
    "    area: str | None\n",
    "    termDef: str\n",
    "\n",
    "    @property\n",
    "    def term(self) -> str:\n",
    "        return self.termDef.split(\" - \")[0]\n",
    "\n",
    "    @property\n",
    "    def definition(self) -> str:\n",
    "        return \" - \".join(self.termDef.split(\" - \")[1:])\n",
    "\n",
    "    @property\n",
    "    def has_definition(self) -> bool:\n",
    "        return len(self.definition) > 0\n",
    "\n",
    "    def term_def_without_uuids(self) -> str:\n",
    "        # Replaces |[a-f0-9-]{36}\\} with \"\\}\"\n",
    "        return re.sub(r\"\\|[a-f0-9-]{36}\\}\", \"}\", self.termDef)\n",
    "\n",
    "    def is_english(self) -> bool:\n",
    "        # Check with regex if text contains only english letters, and some special characters\n",
    "        return re.match(r\"^[a-zA-Z0-9\\s{}\\+\\-—\\.,\\|\\(\\)/';]+$\", self.termDef) is not None\n",
    "\n",
    "    def has_russian(self) -> bool:\n",
    "        return re.search(r\"[а-яА-Я]+\", self.termDef) is not None\n",
    "\n",
    "    def is_balanced(self) -> bool:\n",
    "        counter = 0\n",
    "        for char in self.termDef:\n",
    "            if char == \"{\":\n",
    "                counter += 1\n",
    "            elif char == \"}\":\n",
    "                counter -= 1\n",
    "\n",
    "            if counter > 1:\n",
    "                return False\n",
    "\n",
    "        return counter == 0\n",
    "\n",
    "\n",
    "\n",
    "class StaticStorage:\n",
    "    def __init__(self, path: Path):\n",
    "        self.path = path\n",
    "        json_data = json.loads(self.path.read_text())\n",
    "        self.name = json_data['name']\n",
    "        self.terms: List[TermData] = []\n",
    "        for term in json_data['terms']:\n",
    "            area = term['area'] if 'area' in term else None\n",
    "            term_data = TermData(area, term['termDef'])\n",
    "            self.terms.append(term_data)\n",
    "\n",
    "    def save(self):\n",
    "        dict_data = {\n",
    "            \"name\": self.name,\n",
    "            \"terms\": []\n",
    "        }\n",
    "\n",
    "        for term in self.terms:\n",
    "            term_dict = {}\n",
    "            if term.area:\n",
    "                term_dict[\"area\"] = term.area\n",
    "            term_dict[\"termDef\"] = term.termDef\n",
    "            dict_data[\"terms\"].append(term_dict)\n",
    "\n",
    "        self.path.write_text(json.dumps(dict_data, indent=4, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    def remove_all_uuids(self):\n",
    "        for term in self.terms:\n",
    "            term.termDef = term.term_def_without_uuids()\n",
    "\n",
    "    def terms_list(self) -> List[str]:\n",
    "        return [item.term for item in self.terms]\n",
    "\n",
    "    def add_term(self, term: str, definition: str, area: str = \"\"):\n",
    "        data = TermData(area, f\"{term} - {definition}\")\n",
    "        self.terms.append(data)\n",
    "\n",
    "    def all_non_eng_terms(self, skip_empty: bool = True) -> List[TermData]:\n",
    "        ret: List[TermData] = []\n",
    "        for term in self.terms:\n",
    "            if skip_empty and not term.has_definition:\n",
    "                continue\n",
    "            if not term.is_english():\n",
    "                ret.append(term)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def all_russian_terms(self, skip_empty: bool = True) -> List[TermData]:\n",
    "        ret: List[TermData] = []\n",
    "        for term in self.terms:\n",
    "            if skip_empty and not term.has_definition:\n",
    "                continue\n",
    "            if term.has_russian():\n",
    "                ret.append(term)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def check_prepositions(self) -> None:\n",
    "        preps = ['an', 'a' ,'of', 'the', 'by']\n",
    "        for term in self.terms:\n",
    "            for prep in preps:\n",
    "                bad_start = r\"{\" + prep + r\"\\b\"\n",
    "                bad_end = r\"\\b\" + prep + r\"}\"\n",
    "                if re.search(bad_start, term.termDef) or re.search(bad_end, term.termDef):\n",
    "                    print(f\"Term: {term.term} has {prep} in definition\")\n",
    "\n",
    "    def check_tag_start_end_with_space(self) -> None:\n",
    "        for term in self.terms:\n",
    "            if \"{ \" in term.termDef or \" }\" in term.termDef:\n",
    "                print(f\"Term: {term.term} has tag start or end with space\")\n",
    "\n",
    "    def check_tags_balance(self) -> None:\n",
    "        for term in self.terms:\n",
    "            if not term.is_balanced():\n",
    "                print(f\"Term: {term.term} has unbalanced tags\")\n",
    "\n",
    "    def check_not_ends_with_dot(self) -> None:\n",
    "        for term in self.terms:\n",
    "            if term.termDef[-1] == \".\":\n",
    "                print(f\"Term: {term.term} ends with dot\")\n",
    "\n",
    "    def validate(self) -> None:\n",
    "        self.check_prepositions()\n",
    "        self.check_tag_start_end_with_space()\n",
    "        self.check_tags_balance()\n",
    "        self.check_not_ends_with_dot()\n",
    "\n",
    "\n",
    "class ChatEngine:\n",
    "    model = \"\"\n",
    "    temp = 0\n",
    "\n",
    "    def __init__(self, model: str = \"gpt-4o-mini\", temp: float = 0):\n",
    "        self.model = model\n",
    "        self.temp = temp\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    role: str\n",
    "    content: str\n",
    "\n",
    "    def to_dict(self) -> Dict[str, str]:\n",
    "        return {\"role\": self.role, \"content\": self.content}\n",
    "\n",
    "class TermChat:\n",
    "    system_message: Message\n",
    "    messages: List[Message] = []\n",
    "    engine: ChatEngine\n",
    "\n",
    "    def __init__(self, engine: ChatEngine, system_message: str):\n",
    "        self.engine = engine\n",
    "        self.system_message = Message(\"system\", system_message)\n",
    "\n",
    "    def _get_messages(self) -> List[Dict[str, str]]:\n",
    "        ret: List[Dict[str, str]] = []\n",
    "        ret.append(self.system_message.to_dict())\n",
    "\n",
    "        for message in self.messages:\n",
    "            ret.append(message.to_dict())\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def get_answer(self, user_message: str = \"\") -> str | None:\n",
    "        if user_message != \"\":\n",
    "            self.messages.append(Message(\"user\", user_message))\n",
    "\n",
    "        response = openai.chat.completions.create(\n",
    "            model=self.engine.model,\n",
    "            messages=self._get_messages(),\n",
    "            temperature=self.engine.temp,\n",
    "        )\n",
    "        answer = response.choices[0].message.content\n",
    "        answer = answer if answer else \"\"\n",
    "        # self.messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        self.messages.append(Message(\"assistant\", answer))\n",
    "        return answer\n",
    "\n",
    "    def clear_messages(self):\n",
    "        self.messages = []\n",
    "\n",
    "\n",
    "data_path: Path = Path(\"../../source/staticDataStorage/data/\").resolve()\n",
    "\n",
    "# bio_storage: StaticStorage = StaticStorage(data_path / \"Biochemistry.json\")\n",
    "glb_storage: StaticStorage = StaticStorage(data_path / \"Global.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446ba34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts\n",
    "\n",
    "continue_term_prompt = \"\"\"\n",
    "You are a terms helper robot\n",
    "your task is to guess, based on the list of terms,\n",
    "which one term, not in the list,\n",
    "is the most relevant to already given terms. Answer with one term please.\n",
    "\"\"\"\n",
    "\n",
    "give_definition_prompt = \"\"\"\n",
    "You are a terms definition robot\n",
    "your task is to give a best possible definition to the user requested term.\n",
    "\n",
    "You should give a definition step by step, according to the this rules:\n",
    "\n",
    "1. Definition should contain only information about what the term intrinsically is,\n",
    "without any information about what the term is not, and what the term is related to.\n",
    "Every entity that can be removed from definition without changing the meaning, should be removed.\n",
    "2. Definition should based on the existing list of terms (list would be provided to you).\n",
    "3. Check if there exist terms that also fit this definition and are not synonymous to the term.\n",
    "4. Definition should be as short as possible.\n",
    "\n",
    "List of existing terms: '''{0}'''\n",
    "\n",
    "User requested definition for term: '''{1}'''\n",
    "\n",
    "Format of answer should be step by step thoughts:\n",
    "Raw term definition: <try to define user term for the first time. format 'term - definition'> <new line>\n",
    "Thoughts about definition: <your thoughts on how this term should be redefined according to rules> <new line>\n",
    "\n",
    "First retry: <try to define user term for the second time. format 'term - definition'> <new line>\n",
    "Thoughts about definition: <your thoughts on how this term should be redefined according to rules> <new line>\n",
    "\n",
    "Final try: <try to define user term for the third time. format 'term - definition'> <new line>\n",
    "\"\"\"\n",
    "\n",
    "# - If there is no provided definition on russian, you should provide a definition in english based on the term itself\n",
    "translate_term_prompt = \"\"\"\n",
    "You are a GPT that is specified in term translation.\n",
    "Your task is to translate terms and definitions from russian to english, saving their format up to the last detail.\n",
    "\n",
    "Format description:\n",
    "- TermDef format: each term should start with a capital letter, and the definition should start with a lowercase letter.\n",
    "- Preserve brackets: If in definition some terms are in brackets, you should save them in brackets in the translation. Brackets type is important!!! Use the same type of brackets as in the original definition.\n",
    "- Keyword Usage: Each definition is carefully crafted with specific details\n",
    "- Scientific answers: each definition should be as precise, scientific and dry as possible. Expect that your user knows difficult conceptions and you should use them. your task is just with definition show how this conceptions are related.\n",
    "- Your translation should be exact, without any additional information\n",
    "- If there is no provided definition on russian, you should also not provide a definition in english - just translate the term itself\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b5b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_term():\n",
    "    engine = ChatEngine(temp=0.5)\n",
    "    chat = TermChat(engine, continue_term_prompt)\n",
    "    terms_str = ' ,'.join(glb_storage.terms_list())\n",
    "    answer = chat.get_answer(terms_str)\n",
    "    print(answer)\n",
    "    chat.clear_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5d8465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_definition(new_term):\n",
    "    terms_str = ' ,'.join(glb_storage.terms_list())\n",
    "\n",
    "    engine = ChatEngine(temp=0.2)\n",
    "    chat = TermChat(engine, give_definition_prompt.format(terms_str, new_term))\n",
    "\n",
    "    answer = chat.get_answer()\n",
    "    print(answer)\n",
    "    chat.clear_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939a297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_term(term, definition, area=\"\"):\n",
    "    glb_storage.add_term(term, definition, area)\n",
    "    glb_storage.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e07cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer all terms from Biochemistry to Global with translation\n",
    "\n",
    "# bio_storage.remove_all_uuids()\n",
    "# bio_storage.save()\n",
    "\n",
    "# r_terms = bio_storage.all_russian_terms(skip_empty=False)\n",
    "# print(f\"Russian terms count: {len(r_terms)}\")\n",
    "\n",
    "# for term_data in bio_storage.all_russian_terms(skip_empty=False):\n",
    "    # print(f\"Term: {term_data.termDef}\")\n",
    "\n",
    "def translate_terms(storage: StaticStorage, limit: int = 50):\n",
    "    term_count = len(storage.terms)\n",
    "    translated_count = 0\n",
    "    for i in range(term_count):\n",
    "        term_data = storage.terms[i]\n",
    "        if not term_data.has_russian():\n",
    "            continue\n",
    "\n",
    "        engine = ChatEngine(temp=0.0)\n",
    "        translator = TermChat(engine, translate_term_prompt)\n",
    "        translator.clear_messages()\n",
    "        print(f\"Src term {i}       : {term_data.termDef}\")\n",
    "        answer = translator.get_answer(term_data.termDef)\n",
    "        term_data.termDef = answer if answer else term_data.termDef\n",
    "        print(f\"Translated term {i}: {term_data.termDef}\")\n",
    "\n",
    "        if translated_count % 10 == 0:\n",
    "            print(f\"Translated {translated_count} terms\")\n",
    "\n",
    "        translator.clear_messages()\n",
    "        translated_count += 1\n",
    "\n",
    "        if translated_count >= limit:\n",
    "            break\n",
    "\n",
    "        storage.save()\n",
    "\n",
    "# translate_terms(bio_storage, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfdbc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move terms from bio to global\n",
    "\n",
    "# for i in range(len(bio_storage.terms)):\n",
    "#     term_data = bio_storage.terms.pop(0)\n",
    "#     term_data.area = 'chem'\n",
    "#     glb_storage.terms.append(term_data)\n",
    "\n",
    "# bio_storage.save()\n",
    "glb_storage.validate()\n",
    "glb_storage.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
